# Status do Projeto: BugsJS Dataset Converter

## ðŸŽ¯ Objetivo do Projeto

Criar um sistema completo para converter o dataset BugsJS para o formato do prompt Kody PR-Reviewer e avaliar as respostas geradas.

### Resultado Desejado

1. **Converter BugsJS** â†’ Formato do prompt Kody PR-Reviewer
2. **Gerar datasets**:
   - Input para o prompt (cÃ³digo + diff)
   - Ground truth para validaÃ§Ã£o (respostas esperadas)
3. **Criar evaluator** para comparar respostas vs ground truth

## ðŸ“ Estrutura do Projeto

```
~/dev/kodus/evaluator/bugjs/
â”œâ”€â”€ converter.py              # Script de conversÃ£o (CRIADO)
â”œâ”€â”€ datasets/                 # Outputs (auto-gerado)
â”œâ”€â”€ venv/                     # Ambiente Python
â””â”€â”€ requirements.txt          # pandas

~/dev/bug-dataset/            # BugsJS clonado
â”œâ”€â”€ Projects/[project]/       # CSVs com metadados
â”‚   â”œâ”€â”€ [project]_bugs.csv   # Info dos bugs
â”‚   â””â”€â”€ [project]_commands.csv
â””â”€â”€ main.py                  # Framework BugsJS
```

## ðŸ“Š Estrutura dos Dados

### BugsJS CSV (Descoberta)
```csv
ID;Bug category;Bugfix patterns;Number of tests;...
1;incorrect feature implementation --> incorrect data processing;IF-APCJ,IF-CC,IF-RBR;247;...
```

### Formato do Prompt Kody (Target)
```
Complete File Content:
[cÃ³digo JavaScript completo]

Code Diff (PR Changes):
## file: 'path/file.js'
@@ -46,7 +46,11 @@
__new hunk__
1 +        if (resolver.isNotCacheable()) {
2 +            return that._resolve(resolver, logger);
__old hunk__
-        // If force flag is used, bypass cache
```

### Ground Truth (Target)
```json
{
  "overallSummary": "Bug Bower-1: CorreÃ§Ã£o...",
  "codeSuggestions": [{
    "relevantFile": "bower/lib/core/PackageRepository.js",
    "language": "javascript",
    "suggestionContent": "CorreÃ§Ã£o: incorrect feature implementation",
    "existingCode": "// cÃ³digo removido",
    "improvedCode": "if (resolver.isNotCacheable()) {...}",
    "oneSentenceSummary": "Corrigir potential issues",
    "relevantLinesStart": "4",
    "relevantLinesEnd": "6",
    "label": "potential_issues"
  }]
}
```

## âœ… O Que Funciona

1. **ConversÃ£o bÃ¡sica funcionando**:
   - âœ… LÃª CSVs do BugsJS corretamente
   - âœ… Faz checkout buggy/fixed via `python3 main.py`
   - âœ… Encontra arquivos .js modificados (exclui testes)
   - âœ… Gera diff no formato correto do prompt
   - âœ… Mapeia categorias BugsJS â†’ labels do prompt
   - âœ… Cria 3 arquivos de saÃ­da

2. **Mapeamento de categorias**:
   ```python
   'incorrect feature implementation' â†’ 'potential_issues'
   'error handling' â†’ 'error_handling'
   'security' â†’ 'security'
   'performance' â†’ 'performance_and_optimization'
   ```

3. **Arquivos gerados**:
   - `bugsjs_with_groundtruth.json` - Dataset completo
   - `bugsjs_input_only.json` - SÃ³ inputs para prompt
   - `bugsjs_groundtruth_only.json` - SÃ³ ground truths

## ðŸ› Problema Atual (CRÃTICO)

### Sintoma
```bash
ðŸ” Ground truth criado: 1 suggestions    # âœ… CriaÃ§Ã£o OK
ðŸŽ¯ Tem ground_truth: False               # âŒ NÃ£o salva!
ðŸ“‹ Debug: 0 ground truths encontrados    # âŒ Lista vazia
```

### DiagnÃ³stico
- Ground truth Ã© **criado** na funÃ§Ã£o `create_ground_truth()`
- Ground truth **nÃ£o Ã© salvo** no objeto `converted_files`
- Resultado: arquivos sem ground truth, evaluator nÃ£o funciona

### PossÃ­vel Causa
Suspeita de que o ground truth estÃ¡ sendo perdido entre:
1. `create_ground_truth()` â†’ retorna objeto correto
2. `converted_files.append()` â†’ adiciona ao array
3. Coleta final â†’ `'ground_truth' in file_data` retorna False

### Logs de Debug
```
âœ“ Bower: 3 bugs
ðŸ› Bug Bower-1
  ðŸ“ 60 arquivos .js encontrados (sem testes)
  ðŸ“ 5 arquivos modificados
  ðŸ” Ground truth criado: 1 suggestions  â† AQUI CRIA
  ðŸ” Ground truth criado: 1 suggestions
  (...)
ðŸ” Bug Bower-1: 5 arquivos
  ðŸ“ Arquivo: bower/lib/core/PackageRepository.js
  ðŸŽ¯ Tem ground_truth: False              â† AQUI PERDE
```

## ðŸ”§ Tentativas de CorreÃ§Ã£o

1. **MudanÃ§a na condiÃ§Ã£o de filtro**: âŒ NÃ£o resolveu
2. **Copy.deepcopy() para evitar referÃªncia**: âŒ NÃ£o resolveu  
3. **Reorganizar ordem de coleta**: âŒ NÃ£o resolveu
4. **Debug detalhado**: âœ… Identificou o ponto de falha

## ðŸ“ PrÃ³ximos Passos

### InvestigaÃ§Ã£o NecessÃ¡ria
1. **Debug na funÃ§Ã£o `process_bug()`**:
   - Verificar se `ground_truth` estÃ¡ no objeto antes do `append()`
   - Adicionar print do objeto completo antes de adicionar ao array

2. **Verificar estrutura de dados**:
   - Confirmar se `converted_files.append()` estÃ¡ preservando o `ground_truth`
   - Verificar se hÃ¡ alguma manipulaÃ§Ã£o posterior que remove o campo

### CorreÃ§Ã£o ProvÃ¡vel
```python
# Adicionar debug no process_bug():
converted_files.append({
    'file_path': file_data['path'],
    'file_content': file_data['fixed_content'],
    'diff_content': prompt_diff,
    'ground_truth': ground_truth
})

# Debug imediato
print(f"DEBUG: converted_files[-1] keys: {converted_files[-1].keys()}")
print(f"DEBUG: has ground_truth: {'ground_truth' in converted_files[-1]}")
```

## ðŸš€ Roadmap Completo

### Fase 1: Corrigir Converter âš ï¸ (ATUAL)
- [ ] Resolver bug do ground truth
- [ ] Testar com mÃºltiplos projetos
- [ ] Validar formato de saÃ­da

### Fase 2: Criar Evaluator
- [ ] Carregar predictions + ground truth
- [ ] MÃ©tricas de avaliaÃ§Ã£o:
  - Accuracy de labels
  - BLEU score para texto
  - Exact match para cÃ³digo
- [ ] RelatÃ³rio de performance

### Fase 3: Teste End-to-End
- [ ] Dataset BugsJS â†’ Prompt â†’ Evaluator
- [ ] Benchmark de diferentes modelos
- [ ] AnÃ¡lise de resultados

## ðŸ› ï¸ Comandos de Teste

```bash
# Ambiente
cd ~/dev/kodus/evaluator/bugjs/
source venv/bin/activate

# Teste individual
python converter.py --bugsjs-path ~/dev/bug-dataset --projects Bower --max-bugs 1

# ConversÃ£o completa
python converter.py --bugsjs-path ~/dev/bug-dataset --projects Bower Express --max-bugs 5
```

## ðŸ“‹ Dados de Teste DisponÃ­veis

| Projeto | Bugs Totais | Status |
|---------|-------------|---------|
| Bower | 3 | âœ… Testado |
| Eslint | 333 | âœ… Testado |
| Express | 27 | âœ… Testado |
| Hessian.js | 9 | âœ… Testado |
| Outros | ~80 | â³ Pendente |

## ðŸŽ¯ CritÃ©rio de Sucesso

**Converter funcionando quando**:
```bash
ðŸ“‹ Debug: 5 ground truths encontrados    # > 0 âœ…
```

**Sistema completo quando**:
- Converter gera ground truth correto
- Evaluator compara predictions vs ground truth
- MÃ©tricas de avaliaÃ§Ã£o funcionam
- Pipeline completo: BugsJS â†’ Prompt â†’ Evaluator â†’ RelatÃ³rio