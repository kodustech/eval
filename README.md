# Code Review Evaluator

A lightweight TypeScript framework that checks whether your **prompt-engineered code review** is actually detecting the same issues you defined as ground-truth.

The project loads sample code, asks an LLM to review it, compares the answer with an expected JSON, and returns an accuracy score ‚Äì all with one command.

---

## üåç Repository Layout

```
.
‚îú‚îÄ examples/               # Ground-truth samples (one folder per scenario)
‚îÇ   ‚îú‚îÄ api_request_manager/
‚îÇ   ‚îÇ   ‚îú‚îÄ file.js         # Original, buggy code
‚îÇ   ‚îÇ   ‚îú‚îÄ diff.txt        # Proposed changes (shown to the reviewer LLM)
‚îÇ   ‚îÇ   ‚îî‚îÄ suggestions.json# Canonical analysis (ground truth)
‚îÇ   ‚îî‚îÄ ‚Ä¶                   # 6 more sample folders
‚îú‚îÄ src/
‚îÇ   ‚îú‚îÄ llm/                # Vendor-specific wrappers (Gemini, OpenAI, Claude)
‚îÇ   ‚îú‚îÄ prompts.ts          # Prompt templates (reviewer & evaluator)
‚îÇ   ‚îú‚îÄ TestCaseLoader.ts   # Loads / parses the examples
‚îÇ   ‚îú‚îÄ Evaluator.ts        # Orchestrates the whole flow
‚îÇ   ‚îú‚îÄ index.ts            # CLI entry point (npm start / npm run dev)
‚îÇ   ‚îî‚îÄ types.ts            # Strongly-typed data contracts
‚îú‚îÄ evaluation_results.json # Generated after a run (accuracy report)
‚îî‚îÄ package.json            # Scripts & dependencies
```

### Test-case folder structure

Each **example** is a sub-directory inside `examples/` and **must** contain exactly three files:

| file                | purpose                                                         |
|---------------------|-----------------------------------------------------------------|
| `file.(js|ts|jsx)`  | Original source code                                            |
| `diff.txt`          | Unified diff with your proposed changes                         |
| `suggestions.json`  | Ground-truth analysis in the expected JSON schema               |

> **Why both `file` and `diff`?**  The reviewer LLM receives *both* artefacts so it can see the current state **and** the intended patch, mimicking a typical pull-request review.

---

## üöÄ Quick Start

```bash
# 1 ‚Äì Install deps
npm install

# 2 ‚Äì Provide API keys (.env in project root)
OPENAI_API_KEY=sk-‚Ä¶
GEMINI_API_KEY=‚Ä¶
ANTHROPIC_API_KEY=‚Ä¶

# 3 ‚Äì Run full evaluation (build + exec)
npm start

# 4 ‚Äì Dev mode (no build, ts-node)
npm run dev
```

Running will:
1. Detect every folder in `examples/`
2. Call the **reviewer** LLM for each sample
3. Feed both ground-truth & LLM answer to the **evaluator** LLM
4. Print per-case accuracy and a global summary
5. Write `evaluation_results.json` with the raw data

---

## ‚öôÔ∏è Configuration

Everything is code-first ‚Äì open (or copy) `src/index.ts` and edit the `EvaluatorConfig`:

```ts
const config: EvaluatorConfig = {
  // Which LLM reviews the code
  reviewerLLM: {
    provider: 'gemini',                // 'gemini' | 'openai' | 'claude'
    model: 'gemini-2.5-pro-preview-06-05',
    apiKey: process.env.GEMINI_API_KEY!,
    temperature: 0,
  },
  // Which LLM judges the review
  evaluatorLLM: {
    provider: 'openai',
    model: 'gpt-4o-mini',
    apiKey: process.env.OPENAI_API_KEY!,
    temperature: 0,
  },
  // Optional: run only a subset of folders (default = all)
  testCases: ['api_request_manager', 'task_queue'],
};
```

Changing `provider` automatically switches to the right SDK thanks to `LLMFactory.ts`.

---

## üß† How It Works

```mermaid
graph TD;
  A[TestCaseLoader] -->|reads| B(file.js & diff.txt)
  A --> C(suggestions.json)
  B & C --> D(createReviewerPrompt)
  D --> E(Reviewer LLM)
  E --> F(parse LLM JSON)
  F & C --> G(createEvaluatorPrompt)
  G --> H(Evaluator LLM)
  H --> I(parse evaluation JSON)
  I --> J(print & write results)
```

1. **TestCaseLoader** reads each example and returns a typed object.
2. **Reviewer Prompt** (see `prompts.ts`) asks the first LLM to produce a JSON array of issues.
3. **Evaluator Prompt** compares that answer with ground-truth using a second LLM.
4. Accuracy is computed from the evaluator JSON and printed.

---

## üì§ Result Schema (`evaluation_results.json`)

```jsonc
[
  {
    "testCase": "api_request_manager",
    "overallMatch": true,
    "overallSimilarity": 93,
    "totalSuggestions": 5,
    "matchedSuggestions": 4,
    "accuracy": 80.0,
    "suggestionMatches": [
      {
        "groundTruth": {/* one suggestion */},
        "llmResponse": {/* matched suggestion or null */},
        "isMatch": true,
        "similarity": 95,
        "reasoning": "Both flagged missing retry on 500 errors‚Ä¶"
      }
    ],
    "detailedAnalysis": "‚Ä¶long string from evaluator LLM‚Ä¶"
  },
  "‚Ä¶more cases‚Ä¶"
]
```

---

## ‚ûï Adding New Examples

1. Create a new folder under `examples/`: `your_feature/`
2. Add `file.js`, `diff.txt`, `suggestions.json` following the same format.
3. Run `npm start` ‚Äì the loader auto-discovers the new folder.

---

## üîç Internals / Source Guide

| file                               | role |
|------------------------------------|------|
| `src/llm/BaseLLM.ts`               | common abstract class (validates config) |
| `src/llm/GeminiLLM.ts`             | Wrapper around **@google/genai** (`GoogleGenAI`) |
| `src/llm/OpenAILLM.ts`             | Wrapper around **openai** SDK (Chat Completions) |
| `src/llm/ClaudeLLM.ts`             | Wrapper around **@anthropic-ai/sdk** |
| `src/llm/LLMFactory.ts`            | `switch` that instantiates the correct wrapper |
| `src/prompts.ts`                   | Markdown prompt templates with JSON specs |
| `src/TestCaseLoader.ts`            | Filesystem helper to read examples |
| `src/Evaluator.ts`                 | The orchestrator (loads ‚ûú prompts ‚ûú calls LLMs ‚ûú aggregates) |

---

## üõ†Ô∏è NPM Scripts

| script         | what it does                                           |
|----------------|--------------------------------------------------------|
| `npm run dev`  | Run `src/index.ts` directly with ts-node               |
| `npm start`    | Compile TypeScript ‚ûú run compiled `dist/index.js`      |
| `npm run test:dev` | Quick sanity test on the first available example |
| `npm run build`| Compile TypeScript to `dist/`                          |

---

## License

MIT 